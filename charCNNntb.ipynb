{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, MaxPool1D, Activation, Embedding, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "from functools import reduce\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/manuelr417/charecterlevel/master/sample_training2.csv\")\n",
    "texts = df.iloc[:,0].to_list()\n",
    "\n",
    "tk =  Tokenizer(num_words=None, char_level=True, oov_token='UNK')\n",
    "tk.fit_on_texts(texts)\n",
    "print(tk.word_index)\n",
    "print(\"word index len: \", len(tk.word_index))\n",
    "\n",
    "sequences = tk.texts_to_sequences(texts)\n",
    "#print(texts[0])\n",
    "#print(sequences[0])\n",
    "\n",
    "lens = [len(x) for i, x in enumerate(sequences)]\n",
    "#print(lens)\n",
    "print(\"max: \", max(lens))\n",
    "sum_ser = reduce(lambda x, y: x + y, lens)\n",
    "print(\"sum \", sum_ser)\n",
    "avg_len = (sum_ser * 1.0)/(len(lens))\n",
    "print(\"avg_len: \", avg_len)\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=1400, padding='post')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np_data = np.array(data)\n",
    "print(\"Shape X \", np_data.shape)\n",
    "xlogs = df.iloc[:, 1].to_list()\n",
    "\n",
    "y_data = np.array(xlogs)\n",
    "\n",
    "print(\"Shape Y \", y_data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Neural net\n",
    "input_size = 1400\n",
    "dimension = 50\n",
    "vocabulary_size = len(tk.word_index)\n",
    "\n",
    "input_layer = Input(shape=(input_size,), name=\"input_layer\")\n",
    "embedding_layer = Embedding(vocabulary_size + 1, dimension, input_length=input_size, name=\"embedding\")(input_layer)\n",
    "num_filters = 64\n",
    "filter_size = 5\n",
    "\n",
    "conv_1 = Conv1D(num_filters, filter_size, activation='relu', name=\"conv1\")(embedding_layer)\n",
    "max_pool1 = MaxPool1D(pool_size=2, name=\"maxpool1\")(conv_1)\n",
    "\n",
    "num_filters = 128\n",
    "filter_size = 5\n",
    "\n",
    "\n",
    "conv_2 = Conv1D(num_filters, filter_size, activation='relu', name=\"conv2\")(max_pool1)\n",
    "max_pool2 = MaxPool1D(pool_size=2, name=\"maxpool2\")(conv_2)\n",
    "\n",
    "num_filters = 256\n",
    "filter_size = 5\n",
    "\n",
    "\n",
    "conv_3 = Conv1D(num_filters, filter_size, activation='relu', name=\"conv3\")(max_pool2)\n",
    "max_pool3 = MaxPool1D(pool_size=2, name=\"maxpool3\")(conv_3)\n",
    "\n",
    "\n",
    "X = Flatten()(max_pool3)\n",
    "\n",
    "dense1 = Dense(64, activation='relu', name=\"dense1\")(X)\n",
    "dense2 = Dense(32, activation='relu', name=\"dense2\")(dense1)\n",
    "\n",
    "output = Dense(1, activation='linear', name=\"dense3\")(dense2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Model(inputs=input_layer, outputs=output)\n",
    "model.compile(optimizer='adam', loss='mae', metrics=['mse', 'mae']) # Adam, categorical_crossentropy\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(np_data, y_data, epochs=10, batch_size= 64, validation_split=0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}